{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ae08a3a-6e13-4ec1-a027-182fd0e6e2b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, datediff\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcbe1945-31f1-422d-b779-5176d94cb11c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Azure ADLS Gen2 Configuration (for accessing Data Lake Storage)\n",
    "storage_account = \"olistetlstg\"\n",
    "application_id = \"46ffc682-cbda-438a-a8c1-a6b7d35163d5\"\n",
    "directory_id = \"9d6a79ac-b59d-4c4f-874b-907514214807\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72ad5653-3919-451e-80a5-da9af49366eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set Spark configuration to authenticate with ADLS Gen2 using OAuth 2.0\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", application_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", \"DJk8Q~Wjb9qjrMr~oW3FtgAEHFo.IcvnJ7ygccrF\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{directory_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d70eb8-7105-4c71-ac13-b271835ee900",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define path to Bronze layer (raw CSV files)\n",
    "base_path = \"abfss://olistdata@olistetlstg.dfs.core.windows.net/bronze/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20e1644b-64c5-4210-9ad1-6968da886a63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load raw CSV datasets from Bronze Layer into DataFrames\n",
    "customers_df = spark.read.csv(base_path + \"olist_customers_dataset.csv\", header=True, inferSchema=True)\n",
    "geolocation_df = spark.read.csv(base_path + \"olist_geolocation_dataset.csv\", header=True, inferSchema=True)\n",
    "order_items_df = spark.read.csv(base_path + \"olist_order_items_dataset.csv\", header=True, inferSchema=True)\n",
    "order_payments_df = spark.read.csv(base_path + \"olist_order_payments_dataset.csv\", header=True, inferSchema=True)\n",
    "order_reviews_df = spark.read.csv(base_path + \"olist_order_reviews_dataset.csv\", header=True, inferSchema=True)\n",
    "orders_df = spark.read.csv(base_path + \"olist_orders_dataset.csv\", header=True, inferSchema=True)\n",
    "products_df = spark.read.csv(base_path + \"olist_products_dataset.csv\", header=True, inferSchema=True)\n",
    "sellers_df = spark.read.csv(base_path + \"olist_sellers_dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bef2f707-619b-4786-8fe3-5e5203c9cabf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Connect to MongoDB to fetch product category translations\n",
    "hostname = \"e8yj8.h.filess.io\"\n",
    "database = \"olistDataNoSQL_represent\"\n",
    "port = \"61004\"\n",
    "username = \"olistDataNoSQL_represent\"\n",
    "password = \"b50530ecbbb0978dc6f199a18427e5c23f30d43a\"\n",
    "\n",
    "# Read from MongoDB and convert to Spark DataFrame\n",
    "uri = f\"mongodb://{username}:{password}@{hostname}:{port}/{database}\"\n",
    "client = MongoClient(uri)\n",
    "mongo_data = pd.DataFrame(list(client[database][\"product_categories\"].find()))\n",
    "mongo_data.drop('_id', axis=1, inplace=True)\n",
    "mongo_sparf_df = spark.createDataFrame(mongo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d555a85b-7fa6-4194-b8e0-214ef99c22e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Data cleaning utility: remove duplicates and null rows\n",
    "def clean_dataframe(df, name):\n",
    "    print(\"Cleaning\", name)\n",
    "    return df.dropDuplicates().na.drop(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4990c29b-20af-4fe8-9eda-db199006965a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning orders_df\n"
     ]
    }
   ],
   "source": [
    "# Clean and cast `orders_df`, and add derived delivery time fields\n",
    "orders_df = clean_dataframe(orders_df, \"orders_df\") \\\n",
    "    .withColumn(\"order_purchase_timestamp\", to_date(col(\"order_purchase_timestamp\"))) \\\n",
    "    .withColumn(\"order_delivered_customer_date\", to_date(col(\"order_delivered_customer_date\"))) \\\n",
    "    .withColumn(\"order_estimated_delivery_date\", to_date(col(\"order_estimated_delivery_date\"))) \\\n",
    "    .withColumn(\"actual_delivery_time\", datediff(\"order_delivered_customer_date\", \"order_purchase_timestamp\")) \\\n",
    "    .withColumn(\"estimated_delivery_time\", datediff(\"order_estimated_delivery_date\", \"order_purchase_timestamp\")) \\\n",
    "    .withColumn(\"Delay Time\", col(\"actual_delivery_time\") - col(\"estimated_delivery_time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f837ce8c-4577-4dea-b08f-c0e051c56fb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast numeric columns in payments\n",
    "order_payments_df = order_payments_df \\\n",
    "    .withColumn(\"payment_sequential\", col(\"payment_sequential\").cast(\"int\")) \\\n",
    "    .withColumn(\"payment_installments\", col(\"payment_installments\").cast(\"int\")) \\\n",
    "    .withColumn(\"payment_value\", col(\"payment_value\").cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbc3656d-def0-4539-b499-a28de6a456a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast item ID to integer\n",
    "order_items_df = order_items_df.withColumn(\"order_item_id\", col(\"order_item_id\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e33383f-a6db-4074-9924-c92ff33c0e35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast product dimensions to long\n",
    "products_df = products_df \\\n",
    "    .withColumn(\"product_name_lenght\", col(\"product_name_lenght\").cast(\"long\")) \\\n",
    "    .withColumn(\"product_description_lenght\", col(\"product_description_lenght\").cast(\"long\")) \\\n",
    "    .withColumn(\"product_photos_qty\", col(\"product_photos_qty\").cast(\"long\")) \\\n",
    "    .withColumn(\"product_weight_g\", col(\"product_weight_g\").cast(\"long\")) \\\n",
    "    .withColumn(\"product_length_cm\", col(\"product_length_cm\").cast(\"long\")) \\\n",
    "    .withColumn(\"product_height_cm\", col(\"product_height_cm\").cast(\"long\")) \\\n",
    "    .withColumn(\"product_width_cm\", col(\"product_width_cm\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "403eb99f-8248-443f-af68-0faf96167ec9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast review score to int\n",
    "order_reviews_df = order_reviews_df.withColumn(\"review_score\", col(\"review_score\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8106ed5f-6a22-4f97-9a4b-d2729e4d0cc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast zip code to int in customers\n",
    "customers_df = customers_df.withColumn(\"customer_zip_code_prefix\", col(\"customer_zip_code_prefix\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b371d38-8b82-4ccb-a680-dc43e8bd439c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast zip code and coordinates in geolocation\n",
    "geolocation_df = geolocation_df \\\n",
    "    .withColumn(\"geolocation_zip_code_prefix\", col(\"geolocation_zip_code_prefix\").cast(\"int\")) \\\n",
    "    .withColumn(\"geolocation_lat\", col(\"geolocation_lat\").cast(\"long\")) \\\n",
    "    .withColumn(\"geolocation_lng\", col(\"geolocation_lng\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cab1ce0c-dcf7-4e74-a319-3188a90bbc2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast zip code in sellers\n",
    "sellers_df = sellers_df.withColumn(\"seller_zip_code_prefix\", col(\"seller_zip_code_prefix\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ef8d03e-e0dd-4c92-b5ff-a81213e9ab2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Enrich product data with translated product category names\n",
    "products_df = products_df.join(mongo_sparf_df, \"product_category_name\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6391cf12-9030-4120-b91c-4a89d8cb3bea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join all datasets to build a wide fact table\n",
    "orders_customers_df = orders_df.join(customers_df, \"customer_id\", \"left\")\n",
    "orders_payments_df = orders_customers_df.join(order_payments_df, \"order_id\", \"left\")\n",
    "orders_items_df = orders_payments_df.join(order_items_df, \"order_id\", \"left\")\n",
    "orders_items_products_df = orders_items_df.join(products_df, \"product_id\", \"left\")\n",
    "final_df = orders_items_products_df.join(sellers_df, \"seller_id\", \"left\")\n",
    "\n",
    "# Remove duplicate column names caused by joins\n",
    "def remove_duplicate_columns(df):\n",
    "    seen = set()\n",
    "    to_drop = []\n",
    "    for col_name in df.columns:\n",
    "        if col_name in seen:\n",
    "            to_drop.append(col_name)\n",
    "        else:\n",
    "            seen.add(col_name)\n",
    "    return df.drop(*to_drop)\n",
    "\n",
    "final_df = remove_duplicate_columns(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05037e4d-e43e-4825-9396-0a0c9560dbce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write to Silver Layer\n",
    "# Save Silver Layer to ADLS (cleaned but still raw structure, mainly for internal exploration)\n",
    "\n",
    "silver_path = \"abfss://olistdata@olistetlstg.dfs.core.windows.net/silver/\"\n",
    "\n",
    "customers_df.write.mode(\"overwrite\").parquet(silver_path + \"dim_customers\")\n",
    "products_df.write.mode(\"overwrite\").parquet(silver_path + \"dim_products\")\n",
    "sellers_df.write.mode(\"overwrite\").parquet(silver_path + \"dim_sellers\")\n",
    "geolocation_df.write.mode(\"overwrite\").parquet(silver_path + \"dim_geolocation\")\n",
    "order_reviews_df.write.mode(\"overwrite\").parquet(silver_path + \"dim_reviews\")\n",
    "order_payments_df.write.mode(\"overwrite\").parquet(silver_path + \"dim_payments\")\n",
    "order_items_df.write.mode(\"overwrite\").parquet(silver_path + \"dim_items\")\n",
    "orders_df.write.mode(\"overwrite\").parquet(silver_path + \"dim_orders\")\n",
    "final_df.write.mode(\"overwrite\").parquet(silver_path + \"fact_orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ea9bc11-4802-465b-8ab7-70e7293aef89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write to Gold Layer (for Synapse)\n",
    "# Save Gold Layer to ADLS (cleaned & curated structure for analytics tools like Synapse or Power BI)\n",
    "\n",
    "gold_path = \"abfss://olistdata@olistetlstg.dfs.core.windows.net/gold/\"\n",
    "\n",
    "customers_df.write.mode(\"overwrite\").parquet(gold_path + \"customers\")\n",
    "products_df.write.mode(\"overwrite\").parquet(gold_path + \"products\")\n",
    "sellers_df.write.mode(\"overwrite\").parquet(gold_path + \"sellers\")\n",
    "geolocation_df.write.mode(\"overwrite\").parquet(gold_path + \"geolocation\")\n",
    "order_reviews_df.write.mode(\"overwrite\").parquet(gold_path + \"reviews\")\n",
    "order_payments_df.write.mode(\"overwrite\").parquet(gold_path + \"payments\")\n",
    "order_items_df.write.mode(\"overwrite\").parquet(gold_path + \"items\")\n",
    "\n",
    "final_df.write.mode(\"overwrite\").parquet(gold_path + \"fact_orders\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-06-24 12:44:40",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}