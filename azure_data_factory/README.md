# âš™ï¸ Azure Data Factory - Data Orchestration

## ğŸ“Œ Overview
This directory contains **Azure Data Factory (ADF)** assets used for **data ingestion and orchestration**.  
ADF pipelines manage the extraction of raw data from multiple sources (HTTP/GitHub, MySQL, MongoDB, SQL Server) and land them into **Azure Data Lake Gen2 (Bronze Layer)**.  

ADF ensures **automation, scheduling, parameterization, and monitoring** of ingestion processes.

---

## ğŸ—‚ Directory Structure

```

azure\_data\_factory/
â”‚â”€â”€ dataset/                       # Datasets (CSV, JSON, SQL, etc.)
â”‚   â”œâ”€â”€ CSVFromLinkedServiceToSink.json
â”‚   â”œâ”€â”€ DataFromGithubViaLinkedService.json
â”‚   â”œâ”€â”€ Json1.json
â”‚   â”œâ”€â”€ MySqlTable1.json
â”‚   â””â”€â”€ SQLtoADLS.json
â”‚
â”‚â”€â”€ linkedService/                 # Linked services (connection configs)
â”‚   â”œâ”€â”€ ADLSForCSV.json
â”‚   â”œâ”€â”€ filessSQLDB.json
â”‚   â”œâ”€â”€ httpGithubLinkedService.json
â”‚   â”œâ”€â”€ JsonFromGithubForLoop.json
â”‚   â””â”€â”€ SQLtoADLSLinkedService.json
â”‚
â”‚â”€â”€ pipeline/                      # Pipelines (ETL workflows)
â”‚   â””â”€â”€ data\_ingestion\_pipeline.json
â”‚
â”œâ”€â”€ ForEachInput.json              # Sample input for ForEach activity
â”œâ”€â”€ diagnostic.json                # Diagnostic config
â”œâ”€â”€ info.txt                       # Metadata/notes

```

---

## ğŸ— Architecture - ADF Pipelines

### ğŸ”¹ Overall ADF Workflow
![ADF Pipeline Overview](../assets/azure_data_factory/adf_all.png)

---

### ğŸ”¹ Linked Services
Connections to **ADLS, SQL, HTTP, GitHub, MongoDB**, etc.
![ADF Linked Services](../assets/azure_data_factory/linkedservices.png)

---

### ğŸ”¹ Lookup Activity
Used for dynamic ingestion (reads metadata/config, e.g., list of files or tables).
![ADF Lookup](../assets/azure_data_factory/lookup.png)

---

### ğŸ”¹ ForEach Activity
Iterates over items (e.g., list of tables, files) to trigger ingestion in parallel.
![ADF ForEach](../assets/azure_data_factory/foreach.png)

---

## âš¡ Key Features
- **Parameterized pipelines** â†’ flexible ingestion (multiple tables/files).  
- **ForEach & Lookup** â†’ dynamic data ingestion from config JSON (`ForEachInput.json`).  
- **Linked Services** â†’ centralized connection configs (SQL DB, HTTP endpoints, ADLS).  
- **Dataset abstraction** â†’ reusable source/sink dataset definitions.  
- **Monitoring & Triggers** â†’ schedule and track pipeline executions.  

---

## ğŸ“Š Usage
1. Import JSON assets into **ADF Studio**:
   - **Manage â†’ Linked services** â†’ upload JSON files.  
   - **Manage â†’ Datasets** â†’ upload dataset JSONs.  
   - **Author â†’ Pipelines** â†’ import pipeline JSON.  
2. Update credentials and ADLS paths.  
3. Debug run pipelines.  
4. Schedule via **Triggers** for automated ingestion.  

---

## ğŸ“š References
- [Azure Data Factory Documentation](https://learn.microsoft.com/en-us/azure/data-factory/introduction)  
- [ADF Linked Services](https://learn.microsoft.com/en-us/azure/data-factory/concepts-linked-services)  
- [ADF ForEach Activity](https://learn.microsoft.com/en-us/azure/data-factory/control-flow-for-each-activity)  
- [ADF Lookup Activity](https://learn.microsoft.com/en-us/azure/data-factory/control-flow-lookup-activity) 
